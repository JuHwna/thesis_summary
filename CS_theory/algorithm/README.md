# 1. 자료구조
## 1. 배열과 리스트
### 배열
- 배열 : 메모리의 연속 공간에 값이 채워져 있는 형태의 자료구조
- 배열의 특징 
   1. 인덱스를 사용하여 값에 바로 접근할 수 있음
   2. 새로운 값을 삽입하거나 특정 인덱스에 있는 값을 삭제하기 어려움. 값을 삽입하거나 삭제하려면 해당 인덱스 주변에 있는 값을 이동시키는 과정이 필요함
   3. 배열의 크기는 선언할 때 지정할 수 있으며 한 번 선언하면 크기를 늘리거나 줄일 수 없음
   4. 구조 간단
   
### 리스트
- 리스트 : 값과 포인터를 묶은 노드라는 것을 포인터로 연결한 자료구조
  - 노드 : 컴퓨터 과학에서 값, 포인터를 쌍으로 갖는 기초 단위를 부르는 말
- 리스트의 특징
   1. 인덱스가 없으므로 값에 접근하려면 head 포인터부터 순서대로 접근해야 함 (값에 접근하는 속도가 느리다.)
   2. 포인터로 연결되어 있으므로 데이터를 삽입하거나 삭제하는 연산속도가 빠름
   3. 선언할 때 크기를 별도롤 지정하지 않아도 됨. 리스트의 크기는 정해져 있지 않으며 크기가 변하기 쉬운 데이터를 다룰 때 적절함
   4. 배열보다 구조가 복잡함(포인터를 저장할 공간이 필요해서)
   
> 파이썬에서는 배열과 리스트를 구분하지 않음

## 2. 구간 합
- 구간 합 : 합 배열을 이용하여 시간 복잡도를 더 줄이기 위해 사용하는 특수한 목적의 알고리즘
- 합 배열 S를 만드는 공식 : S[i]=S[i-1]+A[i]
- 구간 합을 구하는 공식 : S[j]-S[i-1]
- 2차원 구간 D[i][j]의 값을 채우는 구간 합 공식
  - D[i][j] = D[i][j-1]+D[i-1][j]-D[i-1][j-1]+A[i][j]
- X<sub>1</sub>, Y<sub>1</sub>, X<sub>2</sub>, Y<sub>2</sub>에 대한 답을 구간 합으로 구하는 방법
  - D[X2][Y2]-D[X1-1][Y2]-D[X2][Y1-1]+D[X1-1][Y1-1]
  
## 3. 투포인터
- 투포인터 : 2개의 포인터로 알고리즘의 시간 복잡도를 최적화함
- 투포인터 이동 원칙
  - sum > N: sum=sum-start_index; start_index++;
  - sum < N: end_index++; sum=sum+end_index;
  - sum== N: end_index++; sum=sum+end_index; count++;
  
## 4. 슬라이딩 윈도우
- 슬라이딩 윈도우 알고리즘 : 2개의 포인터로 범위를 지정한 다음, 범위를 유지한 채로 이동하여 문제를 해결함


## 5. 스택과 큐
- 스택과 큐 : 리스트에서 조금 더 발전한 형태의 자료구조

### 스택과 큐의 핵심 이론
#### 스택
- 스택 : 삽입과 삭제 연산이 후입선출로 이뤄지는 자료구조
  - 후입선출 : 삽입과 삭제가 한 쪽에서만 일어나는 특징이 있음
    - 가장 마지막에 넣었던 값이 나오게 되는 것
    - 후입선출 개념 자체가 재귀 함수 알고리즘 원리와 일맥상통함
  - **깊이 우선 탐색**, **백트래킹 종류**의 코딩 테스트에 효과적임
  
- 파이썬의 스택(리스트로 구현할 수 있음)
  - 위치
    - top : 삽입과 삭제가 일어나는 위치를 뜻함
  - 연산(리스트 이름이 s일때)
    - s.append(data) : top 위치에 새로운 데이터를 삽입하는 연산
    - s.pop() : top 위치에 현재 있는 데이터를 삭제하고 확인하는 연산
    - s[-1] : top 위치에 현재 있는 데이터를 단순 확인하는 연산

#### 큐
- 큐: 삽입과 삭제 연산이 선입선출로 이뤄지는 자료구조
  - 스택과 다르게 먼저 들어온 데이터가 먼저 나감
  - 삽입과 삭제가 양방향에서 이뤄짐
  - 너비 우선 탐색에서 자주 사용
  
- 파이썬의 큐(deque를 이용)
  - 위치
    - rear : 큐에서 가장 끝 데이터를 가리키는 영역
    - front : 큐에서 가장 앞의 데이터를 가리키는 영역
  - 연산(리스트 이름이 s일때)
    - s.append(data) : rear 부분에 새로운 데이터를 삽입하는 연산
    - s.popleft() : front 부분에 있는 데이터를 삭제하고 확인하는 연산
    - s[0] : 큐의 맨 앞(front)에 있는 데이터를 확인할 때 사용하는 연산
 
~~~
우선순위 큐도 있음
- 우선순위 큐: 값이 들어간 순서와 상관 없이 우선순위가 높은 데이터가 먼저 나오는 자료구조
  - 큐 설정에 따라 front에 항상 최댓값과 최솟값이 위치함
  - 일반적으로 힙을 이용해 구현
  - 힙은 트리 종류 중 하나
~~~  


# 2. 정렬

|정렬 알고리즘|정의|
|------------|----|
|버블(bubble)|데이터의 인접 요소끼리 비교하고 swap 연산을 수행하며 정렬하는 방식|
|삽입(selection)|대상에서 가장 크거나 작은 데이터를 찾아가 선택을 반복하면서 정렬하는 방식|
|삽입(insertion)|대상을 선택해 정렬된 영역에서 선택 데이터의 적절한 위치를 찾아 삽입하면서 정렬하는 방식|
|퀵(quick)|pivot 값을 선정해 해당 값을 기준으로 정렬하는 방식|
|병합(merge)|이미 정렬된 부분 집합들을 효율적으로 병합해 전체를 정렬하는 방식|
|기수(radix)|데이터의 자릿수를 바탕으로 비교해 데이터를 정렬하는 방식|

## 1. 버블 정렬
- 버블 정렬 : 두 인접한 데이터의 크기를 비교해 정렬하는 방법
  - 시간 복잡도 : O(n<sup>2</sup>)-> 다른 정렬 알고리즘보다 속도가 느린 편
  - 루프를 돌면서 인접한 데이터 간의 swap 연산으로 정렬함
- 버블 정렬 과정
   1. 비교 연산이 필요한 루프 범위를 설정함
   2. 인접한 데이터 값을 비교함
   3. swap 조건에 부합하면 swap 연산을 수행함
   4. 루프 범위가 끝날 때까지 2,3을 반복함
   5. 정렬 영역을 설정한다. 다음 루프를 실행할 때는 이 영역을 제외함
   6. 비교 대상이 없을 때까지 1~5를 반복함
   
## 2. 선택 정렬
- 선택 정렬 : 대상 데이터에서 최대나 최소 데이터를 데이터가 나열된 순으로 찾아가며 선택하는 방법
  - 구현 방법이 복잡
  - 시간 복잡도 : O(n<sup>2</sup>) -> 효율적이지 않아 코딩 테스트에서는 사용하지 않음

- 선택 정렬의 핵심 이론
  - 최솟값 또는 최댓값을 찾고 남은 정렬 부분의 가장 앞에 있는 데이터와 swap하는 것이 핵심
  
- 선택 정렬 과정
   1. 남은 정렬 부분에서 최솟값 또는 최댓값을 찾음
   2. 남은 정렬 부분에서 가장 앞에 있는 데이터와 선택된 데이터를 swap함
   3. 가장 앞에 있는 데이터의 위치를 변경해 남은 정렬 부분의 범위를 축소함
   4. 전체 데이터 크기만큼 index가 커질 때까지, 즉 남은 정렬 부분이 없을 때까지 반복함.
   

## 3. 삽입 정렬
- 삽입 정렬 : 이미 정렬된 데이터 범위에 정렬되지 않은 데이터를 적절한 위치에 삽입시켜 정렬하는 방식
  - 시간 복잡도 : O(n<sup>2</sup>) -> 느린 편이지만 구현하기 쉬움

- 삽입 정렬의 핵심 이론 : 선택 데이터를 현재 정렬된 데이터 범위 내에서 적절한 위치에 삽입하는 것이 핵심

- 삽입 정렬 수행 방식
   1. 현재 index에 있는 데이터 값을 선택함
   2. 현재 선택한 데이터가 정렬된 데이터 범위에 삽입될 위치를 탐색함
   3. 삽입 위치부터 index에 있는 위치까지 shift 연산을 수행함
   4. 삽입 위치에 현재 선택한 데이터를 삽입하고 index++ 연산을 수행함
   5. 전체 데이터의 크기만큼 index가 커질 때까지, 즉 선택할 데이터가 없을 때까지 반복함
 
 - 적절한 삽입 위치를 탐색하는 부분에서 이진 탐색 등과 같은 탐색 알고리즘을 사용하면 시간 복잡도를 줄일 수 있음
 
 ## 4. 퀵 정렬
 - 퀵 정렬 : 기준값(pivot)을 선정해 해당 값보다 작은 데이터와 큰 데이터로 분류하는 것을 반복해 정렬하는 알고리즘
   - 기준값이 어떻게 선정되는지가 시간 복잡도에 많은 영향을 미침
     - 평균적인 시간 복잡도 : O(nlogn)
     - 최악의 경우의 시간 복잡도 : O(n<sup>2</sup>)

- 퀵 정렬의 핵심 이론
  - 기준값을 중심으로 계속 데이터를 2개의 집합으로 나누면서 정렬하는 것이 핵심

- 퀵 정렬 과정
   1. 데이터를 분할하는 기준 값을 설정함
   2. 기준값을 기준으로 다음 a~e 과정을 거쳐 데이터를 2개의 집합으로 분리함


      a. start가 가리키는 데이터가 기준값이 가리키는 데이터보다 작으면 start를 오른쪽으로 1칸 이동
      
      b. end가 가리키는 데이터가 기준값이 가리키는 데이터보다 크면 end를 왼쪽으로 1칸 이동
      
      c. start가 가리키는 데이터가 기준값이 가리키는 데이터보다 크고 end가 가리키는 데이터가 기준값이 가리키는 데이터보다 작으면 start, end가 가리키는 데이터를 swap하고 start는 오른쪽, end는 왼쪽으로 1칸씩 이동
      
      d. start와 end가 만날 때까지 a~c를 반복함
      
      e. start와 end가 만나면 만난 지점에서 가리키는 데이터와 기준값이 가리키는 데이터를 비교하여 기준값이 가리키는 데이터가 크면 만난 지점의 오른쪽에, 작으면 만난 지점의 왼쪽에 기준값이 기리키는 데이터를 삽입함
   3. 분리 집합에서 다시 기준값을 선정함
   4. 분리 집합이 1개 이하가 될 때까지 과정 1~3을 반복함
   
- 퀵 정렬의 시간 복잡도는 비교적 준수하여 코딩 테스트에서도 종종 응용함
  - 재귀 함수의 형태로 직접 구현해보셈

## 5. 병합 정렬
- 병합 정렬 : 분할 정복 방식을 사용해 데이터를 분할하고 분할한 집합을 정렬하며 합치는 알고리즘
  - 분할 정복 방식 : 주어진 문제를 작은 사례로 나누고 각각의 작은 문제들을 해결하여 정복하는 방법
  - 시간 복잡도 : O(nlogn)

- 병합 정렬의 핵심 이론
  - 가장 작은 데이터 집합으로 분할
  - 병합하면서 정렬한다

- 병합 정렬 수행 방식
   1. 42, 32, 24, 60, 15, 5, 90, 45
   2. [42], [32], [24], [60], [15], [5], [90], [45]
   3. [32,42], [24,60], [5,15], [45,90]
   4. [24,32,42,60], [5,15,45,90]
   5. [5,15,24,32,42,45,60,90]

- 병합 정렬은 코딩 테스트의 정렬 관련 문제에서 자주 등장함

- 2개의 그룹을 병합하는 과정
  - 투 포인터 개념을 사용하여 왼쪽, 오른쪽 그룹을 병합함
  - 왼쪽 포인터와 오른쪽 포인터의 값을 비교하여 작은 값을 결과 배열에 추가하고 포인터를 오른쪽으로 1칸 이동시킴
  - 반드시 숙지 필요
  

## 6. 기수 정렬
- 기수 정렬 : 값을 비교하지 않는 특이한 정렬
  - 값을 놓고 비교할 자릿수를 정한 다음 해당 자릿수만 비교함
  - 시간 복잡도 : O(kn) -> k는 데이터의 자릿수를 말함

- 기수 정렬의 핵심 이론
  - 10개의 큐를 이용함
  - 각 큐는 값의 자릿수를 대표함
  - (ex) 일의 자릿수를 기준으로 데이터 저장 후 데이터 정렬 -> 십의 자릿수를 기준으로 데이터 저장 후 데이터 저장
    - 원본 배열 : 16, 80, 18, 77, 03, 24, 88, 23
    - 일의 자릿수 기준으로 배열 원소를 큐에 집어넣음
    - 0번째 큐부터 9번째 큐까지 pop을 진행함
    - 결과 : 80, 03, 23, 24, 16, 77, 18, 88
    - 십의 자릿수를 기준으로 같은 과정을 진행함
    - 마지막 자릿수를 기준으로 정렬할 때까지 앞의 과정 반복

- 기수 정렬은 시간 복잡도가 가장 짧은 정렬임
  - 코딩 테스트에서 정렬해야 하는 데이터의 개수가 너무 많으면 기수 정렬 알고리즘 활용


# 3. 탐색
- 주어진 데이터에서 자신이 원하는 데이터를 찾아내는 알고리즘

## 1. 깊이 우선 탐색(DFS: depth-first search)
- 깊이 우선 탐색 : 그래프 완전 탐색 기법 중 하나
  - 그래의 시작 노드에서 출발하여 탐색할 한 쪽 분기를 정하여 최대 깊이까지 탐색을 마친 후 다른 쪽 분기로 이동하여 다시 탐색을 수행하는 알고리즘
  
|기능|특징|시간 복잡도(노드 수 :V, 에지 수:E)|
|----|---|--------------------------------|
|그래프 완전 탐색|재귀 함수로 구현, 스택 자료구조 이용|O(V+E)|

- 실제 구현 시 재귀 함수를 이용함 -> 스택 오버플로에 유의해야 함
  - 스택 오버플로 : 지정한 스택 메모리 사이즈보다 더 많은 스택 메모리를 사용하게 되어 에러가 발생하는 상황
- 깊이 웅선 탐색을 응용하여 풀 수 있는 문제 : 단절점 찾기, 단절선 찾기, 사이클 찾기, 위상 정렬 등

- **깊이 우선 탐색의 핵심 이론**
  - 한 번 방문한 노드를 다시 방문하면 안 되므로 노드 방문 여부를 체크할 리스트가 필요함
  - 그래프는 인접 리스트로 표현함
  - 탐색 방식 : 후입선출 특성을 가지므로 스택을 사용하여 설명함
     1. DFS를 시작할 노드를 정한 후 사용할 자료구조 초기화하기
       - DFS를 위해 필요한 초기 작업 : 인접 리스트로 그래프 표현하기, 방문 리스트 초기화하기, 시작 노드 스택에 삽입하기
     2. 스택에서 노드를 꺼낸 후 꺼낸 노드의 인접 노드를 다시 스택에 삽입하기
       - POP을 수행하여 노드를 꺼내고 꺼낸 노드를 탐색 순서에 기입하고 인접 리스트의 인접 노드를 스택에 삽입하여 방문 리스트를 체크함
     3. 스택 자료구조에 값이 없을 때까지 반복하기
       - 앞선 과정을 스택 자료구조에 값이 없을 때까지 반복함
       - 이미 다녀간 노드는 방문 리스트를 바탕으로 재삽입하지 않는 것이 핵심
  - 문제 풀때는 재귀 함수로 구현함
  

## 2. 너비 우선 탐색(BFS: breadth-first search
- 너비 우선 탐색 : 그래프를 완전 탐색하는 방법 중 하나
  - 시작 노드에서 출발해 시작 노드를 기준으로 가까운 노드를 먼저 방분하면서 탐색하는 알고리즘
  
|기능|특징|시간 복잡도(노드 수: V, 에지 수: E)|
|----|---|---------------------------------|
|그래프 완전 탐색| FIFO 탐색, Queue 자료구조 이용|O(V+E)|

- 선입선출 방식으로 탐색하므로 큐를 이용해 구현해야함
- 탐색 시작 노드와 가까운 노드를 우선하여 탐색하므로 목표 노드에 도착하는 경로가 여러 개일 때 최단 경로를 보장함

- **너비 우선 탐색의 핵심 이론**
   1. BFS를 시작할 노드를 정한 후 사용할 자료구조 쵝화하기
      - DFS와 마찬가지로 방문했던 노드는 다시 방문하지 않으므로 방문한 노드를 체크하기 위한 리스트가 필요함
      - 그래프를 인접 리스트로 표현하는 것도 DFS와 동일함
      - 차이점 : 탐색을 위해 스택이 아닌 큐를 사용함
      - 시작 노드를 큐에 삽입하며 방문 리스트를 체크한 것을 보여줌
   2. 큐에서 노드를 꺼낸 후 꺼낸 노드의 인접 노드를 다시 큐에 삽입하기
      - 큐에서 노드를 꺼내면서 인접 노드를 큐에 삽입함
      - 이때 방문 리스트를 체크하여 이미 방문한 노드는 큐에 삽입하지 않음
      - 큐에서 꺼낸 노드는 탐색 순서에 기록함
   3. 큐 자료구조에 값이 없을 때까지 반복하기
      - 큐에 노드가 없을 때까지 앞선 과정을 반복함


## 3. 이진 탐색
- 이진 탐색 : 데이터가 정렬돼 있는 상태에서 원하는 값을 찾아내는 알고리즘
  - 대상 데이터의 중앙값과 찾고자 하는 값을 비교해 데이터의 크기를 절반씩 줄이면서 대상을 찾음

|기능|특징|시작 복잡도|
|----|---|-----------|
|타깃 데이터 탐색|중앙값 비교를 통한 대상 축소 방식|O(logN)|

- 정렬 데이터에서 원하는 데이터를 탐색할 때 사용하는 가장 일반적인 알고리즘
- 구현 및 원리가 비교적 간단하므로 많은 코딩 테스트에서 부분 문제로 요구하는 영역


- 이진 탐색의 핵심 이론 : 오름 차순으로 정렬된 데이터에서 다음 4가지 과정을 반복함
  - 이진 탐색 과정
     1. 현재 데이터셋의 중앙값을 선택함
     2. 중앙값>타깃 데이터일 때 중앙값 기준으로 왼쪽 데이터셋을 선택함
     3. 중앙값<타깃 데이터일 때 중앙값 기준으로 오른쪽 데이터셋을 선택함
     4. 과정1~3을 반복하다가 중앙값 == 타깃 데이터일 때 탐색을 종료함


# 4. 그리디
- 그리디 알고리즘 : 현재 상태에서 볼 수 있는 선택지 중 최선의 선택을 하는 알고리즘
  - 동적 계획법보다 구현하기 쉽고 시작 복잡도가 우수함
  - but, 단점: 항상 최적의 해를 보장하지 못함
  - 코딩 테스트에서 그리디 알고리즘을 사용하기 전에는 항상 그리디 알고리즘을 적용할 때의 논리 유무를 충분히 살펴야함
  
  

# CHAPTER 5. GPU 효율적인 학습
- 딥러닝 모델이 입력 데이터를 처리해 결과를 내놓을 때까지 많은 곱셉 연산을 처리함
  - GPU : 단순한 곱셈을 동시에 여러 개 처리하는 데 특화된 처리 장치

- 최근 LLM의 등장과 함께 모델의 크기가 커지면서 하나의 GPU에 모델을 올리지 못하거나 모델의 학습과 추론을 위해 더 많은 GPU가 필요해졌음
  - 이런 상황을 개선하고 더 많은 사람이 발전된 AI기술을 사용할 수 있도록 GPU를 효율적으로 활용할 수 있는 방법을 찾기 위한 기술 발전이 빠르게 이뤄지고 있음
  - GPU를 효율적으로 사용해 모델을 학습시키는 다양한 기술을 살펴봄
     1. 딥러닝 모델의 저장과 연산에 사용하는 데이터 타입에 대해 알아봄
     2. GPU에서 딥러닝 연산을 수행할 경우 어떤 데이터가 메모리를 사용하는지 살펴봄
     3. GPU를 1개 사용할 때도 메모리를 효율적으로 활용할 수 있는 방법 : 그레이디언트 누적, 그레이디언트 체크포인팅
     4. GPU를 여러 개 사용하는 분산 학습 : 분산 학습 시 같은 데이터가 여러 GPU에 저장돼 비효율적으로 사용되는 문제를 해결한 마이크로소프트의 딥스피드 제로에 살펴봄
     5. LORA : LLM은 모델 파라미터가 많아 모델 전체를 학습시킬 경우 GPU 메모리가 많이 필요한데 전체 모델을 업데이트하지 않고 모델의 일부만 업데이트
     6. QLORA : LORA에서 한 발 더 나아가 모델을 적은 비트를 사용하는 데이터 타입으로 저장해 메모리 효율성을 높임


## 5.1 GPU에 올라가는 데이터 살펴보기
- OOM(Out of Memory) 에러
  - 딥러닝 모델을 학습시키고 추론하기 위해 GPU를 사용할 때 가장 자주 만나는 에러
  - 한정된 GPU 메모리에 데이터가 가득 차 더 이상 새로운 데이터를 추가하지 못해 발생하는 에러
- GPU 메모리에 어떤 데이터가 올라갈까?
  - 딥러닝 모델 자체가 올라감
    - 딥러닝 모델 : 수많은 행렬 곱셈을 위한 파라미터의 집합
    - 각각의 파라미터는 소수 또는 정수 형식의 숫자
  - 모델 이외에 데이터가 올라감
    - 허깅페이스에서 필요한 메모리 사용량을 계산해 제공하는 모델 메모리 계산기 기능
    - 모델의 학습과 추론에 필요한 메모리를 코드로 확인하는 방법

### 5.1.1 딥러닝 모델의 데이터 타입
- 컴퓨터에서는 

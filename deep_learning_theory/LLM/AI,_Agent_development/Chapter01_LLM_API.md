# Chapter 01. LLM API의 기초
- 오픈 ai의 에이전트 SDK처럼 직접 AI 에이전트 개발을 지원한는 경우도 있지만 대부분 경우 기존 API 위에 레이어를 한층 쌓아올린 형태가 되기 때문임

## 1.1 LLM API를 왜 사용해야 하는가?
- LLM API : 대규모 언어 모델에 프롬프트와 파라미터를 주고 추론하게 하는 API
  - 대표적 : 오픈 AI의 API, 클로드의 API, 제미나이 API 등

- 번거롭게 API를 사용해서 LLM으로 추론을 하여 답변을 받도록 하는 근본적인 이유 : AI를 서비스에 적용하기 위해서
  - 만드는 서비스의 사용자가 직접 타이핑을 해서 챗GPT에 프롬프트를 입력하도록 할 수는 없기 때문임
- LLM API를 사용해야만 서비스에 적용할 수 있음
  - LLM이 가지고 있는 능려과 기능의 최대치를 끌어내는 것이 목표라면 LLM API를 사용해야 함
 

## 1.2 LLM API의 기본적인 사용법
- 오픈 AI와 클로드 둘 다 사용법이 크게 다르지 않음

### 1.2.1 모델별 특징을 잘 이해하고 사용하자
- LLM API 사용 시에 주의할 점 중 하나는 모델의 특징을 잘 이해하고 사용해야 한다는 점
- 모델의 특징을 알아야 하는 이유
  - 비용
  - 컨텍스트 윈도우 크기, 응답 속도, 특정 태스크에서의 정확도, 프롬프트 엔지니어링 방식 등이 모델마다 다름
  - 위의 특징을 이해해야 최상의 사용자 경험을 제공할 수 있음
 
### 1.2.2 오픈 AI API의 사용법
- 오픈 AI의 API를 사용하기 위해 REST API를 사용하는 방법도 있음
- 파이썬용 SDK를 사용하는 것이 가장 편함(pip install openai로 쉽게 설치 가능)
- 오픈 AI의 API에는 텍스트 생성 관련된 API가 꽤 다양한 버전으로 있음
  - Chat Compeletion(챗 컴플리션)API : 오픈 AI의 모델에 단순한 질의를 할 때 좋은 API
    - 장점 : 기능이 단순하기 때문에 구현이 쉬움
    - 단점 : 이전 대화를 기억하지 못하는 단점이 있음
    - 

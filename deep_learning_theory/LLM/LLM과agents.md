# 1. LLM과 Agents
## (1) Agent
### 에이전트 이해
- 에이전트의 개념과 다양한 응용
  - step 1: Understand what are Agents
  - step 2: Learn what are LLMs and Messages System
  - step 3: Study Tools and Actions
  - step 4: Learn the Agent workflow
  - step 5: Code your first Agent

- 에이전트 순서를 통한 예시
  - 명령 받기
  - 명령 이해하기(Reason and plan)
    - 자연어 이해 : 자연어를 이해하기 때문에 우리의 요청을 빠르게 파악
    - 추론과 계획 : 주문을 이행하기 전에 추론과 계획을 통해 필요한 단계와 툴을 파악함
    - 행동 계획
  - 실행하기
    - 행동 실행 : 계획을 실행하기 위해 자신이 알고 있는 도구 박스에서 툴을 사용
    - 커피 만들기 : 커피를 내리기 위해 커피 머신을 작동
    - 커피 제공
   
- 에이전트의 개념
  - 추론, 계획, 플랫폼과 상호작용할 수 있는 AI모델
  - 능동성, 즉 플랫폼과 상호작용할 수 있는 능력이 있음
  - User Request -> Step 1: Think and Plan -> Step 2: Act using Tools
 
### 에이전트의 정의
- 에이전트란
  - 사용자가 정의한 목표를 달성하기 위해 플랫폼과 상호작용하는 AI모델을 활용하는 시스템
  - 작업을 수행하기 위해 추론, 계획, 그리고 액션(외부 툴을 통해) 실행을 결합
- 에이전트의 구성 요소
  - 두뇌(AI모델)
    - 모든 사고가 일어나는 곳
    - 추론과 계획을 처리
    - 상황에 기반하여 어떤 액션을 취할지 결정
  - 몸 (기능과 툴)
    - 에이전트가 할 수 있는 모든 것
    - 에이전트에 사전 구성된 툴과 능력에 따라 액션의 범위가 결정됨
    - 예시(사람)
      - "걷기", "달리기", "뛰기", "잡기" : 실행 가능
      - "날기" : 실행 불가능(날개가 없기 때문에)
- 에이전트에 사용되는 AI모델
  - LLM(대규모 전이 모델)
    - 입력 : 텍스트
    - 출력 : 텍스트
    - 예시 : OpenAI의 GPT4, Meta의 Llama, Google의 Gemini
  - 그 외
    - 입력 : 텍스트 외 다른 입력 (이미지 등)
    - 예시 : VLM
      - LLM과 유사
      - 입력으로 이미지도 가능


- 에이전트의 툴(AI가 다양한 액션을 취할 수 있는 방법)
  - LLM은 엄청난 모델이지만 오직 텍스트만 생성할 수 있음
  - ChatGPT 같은 어플리케이션으로 이미지를 생성 가능
    - 개발자들이 추가 기능(툴)을 구현했기 때문
    - LLM은 이 툴을 사용하여 다양한 액션 실행 가능

- 에이전트는 어떤 종류의 작업을 수행할 수 있는지? : 툴을 통해 액션을 완료하도록 구현된 모든 작업
  - 예시
    - 개인 비서(시리) 역할을 하는 에이전트
    - 에이전트가 이메일을 보낼 때마다 사용할 수 있는 툴 작성
    - 요청 : 관리자에게 오늘 회의 연기를 요청하는 이메일 발송
    - 액션 : 이메일 발송
  - 참고
    - 액션은 툴과 같지 않음
    - 액션은 하나의 작업을 완료하기 위해 여러 툴을 사용

- 에이전트 활용 사례
  - 개인 가상 비서
    - 사용자의 요청을 이해
    - 필요한 정보를 찾아 제공
    - 특정 작업을 수행
    - 예시 : Siri, Alexa, Google, Assistant
  - 고객 서비스 챗봇
    - 고객과 대화를 통해 상호작용하는 챗봇
      - 질문에 대한 답 생성
      - 문제 해결 단계 안내
      - 내부 DB에 문의 접수
      - 트랜잭션 완료
  - 비디오 게임의 AI NPC
    - 동적인 NPC 제작 가능
      - 상황에 맞게 응답
      - 플레이어 상호작용에 적응
      - 동적인 대화를 생성 가능
     
- 에이전트 정의 : AI 모델을 AI 추론 모듈로 사용하는 시스템
  - 자연어 이해 : 의미있는 방식으로 사용자의 요청을 해석하고 응답
  - 추론 및 계획 : 정보를 분석하고 결정, 문제 해결을 위한 전략 수립
  - 액션 실행 : 정보를 수집하고 액션 실행, 해당 액션의 결과를 관찰

## (2) LLM
### 1. LLM의 기본 개념과 아키텍처
- LLM이란?
  - 대규모 언어모델(Large Language Model)
  - 인간의 언어를 이해하고 생성하는 데 탁월한 AI모델
  - 방대한 양의 텍스트 데이터를 통해 언어의 패턴, 구조, 늬앙스까지 학습 가능
  - 일반적으로 수백만 개의 매개변수로 구성
- 시퀀스란?
  - LLM에서 순차적으로 나열된 토큰들의 묶음
  - Sequence Length = 토큰 수/단어 수
- 트랜스포머 아키텍처 기반 모델
  - 어텐션 메커니즘(Attention Mechanism)
    - 2018년 구글의 BERT 출시 이후 주목받은 딥러닝 아키텍처
  - 인코더 기반 트랜스포머
    - 텍스트(또는 데이터)를 입력으로 받아 해당 텍스트의 의미(또는 임베딩)을 출력
      - 예시 : 구글의 BERT
      - 사용 사례 : 텍스트 분류, 의미 검색, 개체명 인식
      - 매개변수 : 수백만 개의 매개변수
  - 디코더 기반 트랜스포머
    - 한 번에 하나의 토큰씩 시퀀스를 완성하기 위해 새 토큰을 생성
    - 예시 : Meta의 Llama
    - 사용 사례 : 텍스트 생성, 챗봇, 코드 생성
    - 매개변수 : 수십억 개의 매개변수
  - Seq2Seq (인코더-디코더) 아키텍처
    - 인코더(입력 시퀀스를 컨텍스트 표현으로 처리)와 디코더(출력 시퀀스 생성) 결합
    - 예시 : T5, BART
    - 사용 사례 : 번역, 요약, 의역
    - 매개변수 : 수백만 개의 매개변수

- LLM은 일반적으로 디코더 기반 모델

|모델|제공사|
|----|------|
|Deepseek-R1|DeepSeek|
|GPT4|OpenAI|
|Llama3|Meta(Facebook AI Research)|
|SmolLM2|Hugging Face|
|Gemma|Google|
|Mistral|Mistral|


#### LLM의 기본 원리
- 이전 토큰의 시퀀스가 주어졌을 때 다음 토큰을 예측하는 것
- 토큰
  - LLM이 작업하는 정보 단위(토큰≠단어)
    - 영어 : 약 60만개의 단어
    - LLM : 약 32000개의 토큰 어휘(Llama2의 경우)
  - 효율성을 위해 LLM은 전체 단어를 사용하지 않음
  - 토큰화 예시
    - interest+ing = insteresting
    - interest+ed = interested

#### LLM의 특수 토큰
- 생성 과정의 구조적 경계를 정의하는 메타데이터 마커 역할
  - 토큰의 다양성과 LLM의 텍스트 생성에서 토큰이 하는 역할을 이해하는 것은 중요함
  - 모델의 구성을 확인하며 특수 토큰에 대해 더 자세하게 확인 가능
    - SmolLM2 모델의 특수 토큰 : tokenizer_config.json
  - 예시
    - 시퀀스의 시작/종료 지점 명시
    - 입력과 출력 영역 분리
    - 모델의 어텐션 메커니즘에 구조적 신호 제공
    - 제로샷, 퓨샷 학습에서 컨텍스트 구조화

- 주요 모델별 특수 토큰

|모델|제공사|EOS토큰|기능|
|----|----|------|-----|
|GPT4|OpenAI|<\|endoftext\|>|메시지 텍스트 끝|
|Llama3|Meta(Facebook AI Research)|<\|eot_id\|>|시퀀스 끝|
|Deepseek-R1|DeepSeek|<\|end_of_sentence\|>|메시지 텍스트 끝|
|SmolLM2|Hugging Face|<\|im_end\|>|지시 또는 메시지 끝|
|Gemma|Google|<end_of_turn>|대화 턴 끝|


### 2. LLM의 작동 원리
- LLM은 EOS에 도달할 때까지 텍스트를 디코딩
  - 입력과 출력 순환 : 한 번의 패스에서 나온 출력이 다음 패스의 입력
  - 자기회귀적 특성 : 자기회귀적 특성을 가짐
  - 종료 조건 : 루프는 모델이 다음 토큰을 EOS 토큰으로 예측할 때까지
 
#### 단일 디코딩 루프
(1) 토큰화 : 입력 텍스트를 토큰화
(2) 시퀀스 계산 : 모델은 각 토큰의 의미와 위치 정보를 포함하는 시퀀스 계산
(3) 모델로 전달 : 앞서 계산한 시퀀스를 모델로 전달
(4) 예측 : 모델은 해당 텍스트에서 시퀀스의 다음 토큰일 가능성을 점수로 매겨 출력

#### 디코딩 전략
- 점수를 기반으로 문장을 완성할 토큰을 선택
- Greedy Search : 최고 점수를 가진 토큰 선택(가장 간단한 전략)
- Beam Search : 개별 토큰의 점수가 낮더라도 최대 총점을 가진 시퀀스 탐색

#### 어텐션(Attention)
- 다음 단어를 예측할 때 문장 내 모든 단어가 동일한 중요도를 가지는 것은 아님
- 다음 토큰을 예측하기 위해 가장 관련성 높은 단어를 식별하는 과정이 필요함
- 긴 시퀀스에 어텐션 매커니즘 작동시키는 측면에서 상당한 발전이 있었음

![image](https://github.com/user-attachments/assets/5f6935cd-6ec6-4925-879f-de1a87ba2a0d)

- 컨텍스트 길이
  - LLM이 처리할 수 있는 최대 토큰수
  - 가질 수 있는 최대 어텐션 범위

### 3. LLM의 훈련 및 활용
#### LLM과 프롬프트
- LLM의 핵심 작업 : 입력된 토큰을 통해 다음 토큰 예측하고 중요한 토큰 선택
  - 이때 입력 시퀀스에 따라 예측 및 선택 결과가 달라질 수 있음
- 프롬프트의 정의 : LLM에 제공하는 입력 시퀀스
- 프롬프트 설계의 중요성 : LLM이 원하는 출력 결과를 더 잘 생성할 수 있도록 프롬프트를 설계해야 함

#### LLM 훈련 방법
- 대규모 데이터셋 훈련
  - 대규모 텍스트 데이터셋
  - 자기 지도 학습(self-supervised) : Label이 없는 Untagged data를 기반으로 한 학습이며 자기 스스로 학습 데이터에 대한 분류를 수행함
  - 마스킹된 언어 모델(masked language) : 시퀀스에서 마스킹된 토큰을 예측하며 모델은 양방향으로 토큰에 액세스할 수 있음
    - 토큰의 왼쪽과 오른쪽 양쪽에서 접근할 수 있음
    - 전체 시퀀스에 대한 문맥적 이해가 필요항 작업에 적합함
- 비지도 학습의 이점
  - 언어의 구조와 텍스트의 기본 패턴 학습
  - 모델이 보지 못한 데이터 일반화 가능
- 미세 조정
  - 초기 사전 훈련 후 특정 작업을 수행하기 위해 미세 조정
  - 지도 학습 목표
 
#### LLM 사용 방법
- A. LLM 추천 사용 방법
  - 로컬에서 실행(하드웨어 성능이 충분할 때)
  - 클라우드/API 사용(예 : Hugging Face API)
- B. AI 에이전트에서 LLM 사용 방법
  - 사용자의 지시를 해석
  - 대화에서 컨텍스트 유지
  - 추론 및 계획
    - LLM은 에이전트의 두뇌
   

### 4. 채팅 템플릿
- 채팅 템플릿을 통해 생성 결과를 구조화
  - 사용자는 일반적으로 채팅 인터페이스를 통해 에이전트와 상호작용
  - 예시 : ChatGPT, Siri 등

#### 채팅 템플릿의 역할
- UI에서 보이는 것과 모델에 입력 되는 프롬프트의 차이

![image](https://github.com/user-attachments/assets/237cd067-78c3-4cfb-a8a8-7eaf4ef36765)

- 대화형 메시지(사용자 및 어시스턴트 대화)와 특정 LLM이 요구하는 입력 형식 사이의 다리 역할
  - 사용자와 에이전트 간의 통신을 구조화하여 각 모델이 고유한특수 토큰을 갖고 있음에도 올바르게 포맷된 프롬프트를 전달받을 수 있도록 함

### 5. 메시지 : LLM의 기본 시스템
#### 시스템 메시지란
- 모델이 어떻게 행동해야하는지 정의
- 에이전트 내에서 계속 영향을 미침
- 대화의 처음부터 끝까지 같은 규칙을 따르게 하는 역할

#### 시스템 메시지의 역할
- 사용 가능한 툴 : 사용 가능한 툴에 대한 정보 제공
- 작업 지정 : 실행할 작업의 형식에 대한 지침 제공
- 사고 과정 : 모델의 사고 과정을 어떻게 세분화할 지에 대한 지침 제공

#### 대화 : 사용자 및 어시스턴트 메시지
- 채팅 템플릿의 역할
  - 대화 이력을 보존하여 컨텍스트를 유지
  - 사용자와 어시스턴트 간의 이전 대화 내용 저장
  - 일관적인 대화 유지 가능
 
#### 채팅 템플릿에 따른 프롬프트 변환

![image](https://github.com/user-attachments/assets/157f14f1-8ab9-43d5-8921-ca2292d0702a)

### 6. 채팅 템플릿의 중요성
- 구조화 : 언어 모델과 사용자 간의 대화를 구조화
- 일관성 : 모델이 이해할 수 있는 일관된 방식으로 프롬프트 포맷
- 변환 : 메시지를 단일 프롬프트로 변환

#### 베이스 모델 vs 인스트럭트 모델
- 베이스 모델 : 원시 텍스트 데이터에서 다음 토큰을 예측하도록 훈련됨
- 인스트럭트 모델 : 지시를 따르고 대화에 참여하도록 미세 조정됨
  - 베이스 모델을 인스트럭트 모델처럼 작동하게 하려면 모델이 이해할 수 있는 일관된 방식으로 프롬프트를 포맷해야 함

#### 채팅 템플릿 이해하기
- 프롬프트 포맷
  - 각 인스트럭트 모델은 서로 다른 형식과 특수 토큰 사용
    - 각 모델이 예상하는 방식으로 프롬프트 포맷 필요
  - 예시 : Jinja2
    - JSON 메시지 목록의 ChatML을 텍스트 표현으로 변환

#### 채팅 템플릿 예시

![image](https://github.com/user-attachments/assets/83828d72-3668-4fab-89d3-3b76c5da9a52)

![image](https://github.com/user-attachments/assets/9645d45b-44d6-4819-a551-524d722e2a61)

#### 모델(채팅 템플릿)에 따른 포맷 형태 비교

![image](https://github.com/user-attachments/assets/0855aeb0-2432-427a-86d7-7b854bc82f2c)

#### 메시지를 프롬프트로

![image](https://github.com/user-attachments/assets/f6482989-d3af-4630-9bcf-6575e01a1021)

- transformers
  - 토큰화 프로세스의 일부를 채팅 템플릿으로 처리 라이브러리
- chat_tmeplate
  - LLM이 대화를 전달받기 위한 메서드
- apply_chat_template
  - 이전 대화를 프롬프트로 변환하기 위한 메서


## (3) 툴(Tools)
### 1. 툴의 개념
- LLM에 제공되는 함수로 명확한 목표가 있음
- AI 에이전트에서 주로 사용되는 툴

|툴|설명|
|--|----|
|웹 검색|에이전트가 인터넷에서 최신 정보를 가져올 수 있게 함|
|이미지 생성|텍스트 설명을 기반으로 이미지 생성|
|검색|외부 소스에서 정보를 검색|
|API 인터페이스|외부 API와 상호작용(GitHub, YouTube, Spotify 등)|

#### 좋은 툴의 특징
- LLM 능력 보완
  - 산술 연산을 수행하는 경우 LLM에 계산기 툴을 제공하면 모델의 기본 기능에 의존하는 것보다 더 나은 결과를 얻을 수 있음
- 최신 데이터 제공 : LLM은 훈련 데이터(훈련 이전의 데이터)를 기반으로 예측
  - 툴을 사용해 최신 데이터 사용 가능
- 명확한 기능 : 툴의 기능이 명확해야 함

#### 툴의 구성 요소
- 툴에 대한 설명 : 함수가 수행하는 작업에 대한 설명
- 호출 요소 : 수행할 수 있는 작업
- 인수 : 유형이 지정된 인수
- 출력 : (선택) 유형이 지정된 출력

### 2. 툴의 작동 방식
- 전체적인 프로세스
  - (1) LLM에 툴 제공 : 텍스트로 툴을 LLM에 전달
    - 명확한 툴 사용법 : 툴이 무엇을 하는지 LLM에 명확하게 전달 필요
      - 툴의 기능, 툴의 입력값
    - 구조화된 형식 : 명확한 툴 사용법 전달 필요
      - 컴퓨터 언어나 JSON과 같은 일관된 형식으로 전달
    - ![image](https://github.com/user-attachments/assets/7ca903d6-57e0-423d-83c0-7addc83dfed7)
    - 툴 설명 자동 포맷팅
      - Python 코드 : 함수 이름, 독스트링, 유형 힌트 사용
      - 자동 텍스트 생성 : Python의 내부 기능을 활용하여 소스 코드에서 툴 설명 자동 추출
      - 데코레이터 : @tool 데코레이터 사용
    - ![image](https://github.com/user-attachments/assets/b40ac57d-657d-4dd4-b7e8-1b9916e10d54)
    
  - (2) LLM의 툴 호출 텍스트 생성 : 필요 시 코드 형태의 텍스트 출력
  - (3) 에이전트의 툴 호출 : LLM 출력을 파싱하고 실제 툴 실행
  - (4) 결과 도출 : 툴 출력을 메시지로 도출

### 3. 일반적인 툴 구현

![image](https://github.com/user-attachments/assets/f2160bdc-db13-4d76-b4ac-a9ef7ce6ffdc)

#### Tool 클래스(init)

![image](https://github.com/user-attachments/assets/f4480ed6-49c8-4d9c-bf86-59ebb01244fd)

- name (str) : 툴의 이름
- desciption (str) : 툴의 기능에 대한 설명
- function (callable) : 툴이 실행하는 함수
- arguments (list) : 예상되는 입력 매개변수
- outputs (str 또는 list) : 툴의 예상 출

#### Tool 클래스(to_string, call)

![image](https://github.com/user-attachments/assets/cbcec2be-adb9-46c2-84ab-56609c337569)

- \_call_() : 툴 인스터스가 호출될 때 함수 도출
- to_string() : 툴의 속성을 텍스트 표현으로 변환

#### Tool 클래스 사용 방법

![image](https://github.com/user-attachments/assets/cd6bd620-c480-4356-af6f-de86a8077a5c)

- @tool 데코레이터를 사용하면 Tool 클래스 사용 가능

#### 시스템 프롬프트

![image](https://github.com/user-attachments/assets/d1dd6017-920f-48fc-b9cf-01458744e004)

#### 툴은 AI 에이전트의 기능을 향상시킴
- 툴의 개념
  - LLM에 추가 기능을 제공하는 함수
- 툴 정의
  - 명확한 설명
  - 입출력
  - 호출 가능한 요소
- 툴의 필요성
  - 정적 모델 훈련의 한계 극복
  - 실시간 작업 처리 가능
  - 특수한 작업 수행 가


## (4) AI 에이전트 워크플로우
### 1. AI 에이전트 워크플로우 개요
#### 사고-행동-관찰 주기
- 사고
  - LLM이 다음 단계를 결정
- 행동
  - 에이전트가 툴을 호출하여 행동을 취함
- 관찰
  - 에이전트가 행동에 대한 결과를 인식

- While 루프를 사용하여 목표에 달성할 때까지 계속됨

![image](https://github.com/user-attachments/assets/a603f463-ea0f-498f-92e6-a4434e9c2359)

#### 워크플로우 예시 : 계산기

![image](https://github.com/user-attachments/assets/97d29441-63cf-4cbd-a2d1-9bb47066a7c4)

#### 워크플로우 예시 : 날씨 에이전트
- 사용자 : 오늘 뉴욕의 날씬는 어떤가요?
- 알프레드 : {날씨 API툴을 사용하여쿼리에 대한 답변 출력}

#### 워크플로우
- 사고(내부 추론)
  - 사용자의 요구사항, 사용할 툴, 필요한 행동 파악
- 행동
  - 사용할 툴과 입력 등을 지정해 툴 호출을 준비
- 관찰
  - 툴을 호출하여 결과를 생성
  - 프롬프트에 결과를 컨텍스트로 추가
    - 행동의 성공 여부 확인 및 정보 제공
- 사고 업데이트
  - 전달받은 결과를 토대로 사고(내부 추론) 업데이트

#### 사고(내부 추론)
- 요구사항
  - 사용자가 뉴욕의 현재 날씨 정보를 필요로 함
- 툴
  - 날씨 데이터를 가져오는 툴에 접근할 수 있음
- 필요한 행동
  - 최신 세부 정보를 얻기 위해서 날씨 API를 호출해야 함

#### AI 에이전트의 핵심 특성
- 반복적인 프로세스
  - 목표 달성까지 사고-행동-관찰 주기 반복
- 툴 통합
  - 외부 툴을 활용해 실시간 데이터를 검색하고 처리
- 동적 적용
  - 새로운 정보를 지속적으로 통합하여 정확한 답변 제공
 
### 2. 사고 : 내부 추론과 Re-Act 접근법
#### 에이전트의 내부 추론과 계획 프로세스
- 정보 분석 : 프롬프트에 제시된 정보를 분석
- 전략화 : 현재 작업을 고려하여 접근 방식 전략화
- 작업 분할 : 복잡한 문제를 더 작고 단순한 단계로 분해
- 지속적인 계획 조정 : 과거 결과 및 새 정보를 바탕으로 계획을 지속적으로 조정 가능

#### 사고(내부 추론)의 유형

|사고 유형|예시|
|--------|----|
|계획수립|이 작업을 세 단계로 나누어야 합니다. 1) 데이터 수집, 2) 트렌드 분석, 3) 보고서 생성|
|분석|오류 메시지를 기반으로 볼 때, 문제는 데이터베이스 연결 매개변수에 있는 것 같습니다.|
|의사 결정|사용자의 예산 제약을 고려할 때 중간 등급 옵션을 추천해야 합니다|
|문제 해결|이 코드를 최적화하려면 먼저 병목 현상을 식별하기 위해 프로파일링해야 합니다|
|메모리 통합|사용자가 이전에 Python에 대한 선호도를 언급했으므로 Python으로 예시를 제공하겠습니다|
|자기 성찰|이전 접근 방식이 잘 작동하지 않았으니 다른 전략을 시도해야 합니다|
|목표 설정|이 작업을 완료하려면 먼저 인수 기준을 설정해야 합니다|
|우선순위 지정|새로운 기능을 추가하기 전에 보안 취약점을 먼저 해결해야 합니다|

#### 추론과 행동을 연결
- LLM이 다음 토큰을 디코딩 하기 전에 프롬프트에 "Let's think step by step"(단계별로 생각하가ㅣ)을 추가
- A. Few-shot
  - 몇 개의 예시를 통해 문제 해결 방법을 학습
- B. Few-shot-CoT

### 3. 행동 : 에이전트와 플랫폼과의 상호 작용

### 4. 관찰 : 피드백 통합을 통한 성찰과 적

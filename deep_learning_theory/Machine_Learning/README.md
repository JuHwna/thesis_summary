# CHAPTER 01. 서론
## 1.3 가설 공간
- 귀납 : '특수'에서 '일반'으로 일반화(generalization)하는 과정
  - 구체적인 사실에서 일반성을 가진 규칙을 찾는 것
  - 귀납 학습(inductive learning) : 샘플을 통해 학습하는 것
- 연역 : '일반'에서 '특수'로 특화(specialization)하는 과정
  - 기초 원리로부터 구체적인 정황을 추론하는 것
- 귀납 학습
  - 좁은 의미 : 훈련 데이터에서 개념을 배울 것을 요구함 -> 개념 학습 or 개념 형성
  - 넓은 의미 : 샘플을 통해 배우는 것
  - 개념 학습 기술 : 현재 연구되거나 응용되는 것이 비교적 많지 않음
    - why? : 일반화 성능이 좋으면서 의미 또한 명확한(해석력이 좋은) 개념을 학습하는 것은 쉽지 않기 때문
    - 이 때문에 현실에서 자주 사용되는 기술은 대부분 블랙박스 모델임
    - 그런데 개념 학습에 대한 이해가 있다면 머신러닝의 기초 사상을 이해하는 데 많은 도움이 됨
    - 개념 학습 중에서 가장 기초 : 부울 개념 학습
      - '예'나 '아니오' 같은 표현을 0/1 불리언값을 가진 목표 개념을 학습하는 것
- 버전 공간(version space)
  - 많은 가설이 훈련 데이터 세트와 일치할 수 있고 훈련 데이터 세트와 일치하는 '가설들의 집합'이 존재함

## 1.4 귀납적 편향
- 학습을 통해 얻은 모델은 가설 공간 중에 하나의 가설에 대응함
  - 어떤 모델(혹은 가설)을 사용해야 할까?
- 구체적인 학습 알고리즘은 반드시 하나의 모델을 생성해 내야함
  - 학습 알고리즘 본연의 '편향'이 중요하게 작용함
- 귀납적 편향(inductive bias) or 편향(bias) : 머신러닝 알고리즘이 학습 과정에서 특정한 유형의 가설에 대한 편향
  - 모든 유효한 머신러닝 알고리즘은 귀납적 편향을 가지고 있음
  - 그렇지 않다면 가설 공간 훈련 데이터상의 '효과가 같아 보이는' 비슷한 가설들 사이에서 혼란에 빠질 수 있으며 확실한 학습 결과를 생성해 낼 수도 없음
  - 학습 알고리즘이 방대한 가설 공간에서 가설들을 선택할 때 가지는 휴리스틱 방법 혹은 가치관 정도로 해석할 수 있음
  - 학습 알고리즘이 내놓은 '어떤 모델이 더 좋은가'에 관한 가설에 대응함
  - 현실의 문제 중에서 이 가설의 성립 여부는 알고리즘이 좋은 성능을 얻을 수 있는지를 결정하게 됨
- 오컴의 면도날(자연과학 연구에서 가장 기본이 되는 원칙)
  - '만약 다수의 가설이 관측된 것과 일치한다면, 가장 간단한 것을 선택해야 한다'라는 원칙
  - 유일한 원칙은 아님

# CHAPTER 02. 모델 평가 및 선택
## 2.1 경험 오차 및 과적합
- 오차율(error rate) : 전체 샘플 수와 잘못 분류한 샘플 수의 비율
  - 오차율 : E = ａ/m
  - 정밀도 : 1 -ａ/m ( 1 - 오차율)
- 오차 : 학습기의 실제 예측 값과 샘플의 실제 값 사이의 차이
  - 훈련 오차(training error) or 경험 오차(empirical error) : 학습기가 훈련 세트상에서 만들어낸 오차
  - 일반화 오차(generalization error) : 학습기가 새로운 샘플 위에서 만들어낸 오차
- 과적합 : 학습기가 훈련 데이터에서 학습을 '과도하게 잘하면', 훈련 데이터 중의 일정한 특성을 모든 데이터에서 내재된 일반 성질이라 오해하게 만듦
  - 일반화 성능이 떨어지는 현상
- 과소적합 : 학습기가 훈련 데이터의 일반 성질을 제대로 배우지 못했다는 뜻
- 과적합을 일으키는 원인
  - 학습능력이 너무 뛰어나 훈련 데이터들이 가진 일반적이지 않은 특성까지 학습하는 경우
  - 해결 방법 : 매우 까다로움
- 과소적합을 일으키는 원인
  - 학습능력이 좋지 못해서인 경우가 많음
  - 해결 방법 
    - ex) 의사결정 트리의 경우는 가지치기, 신경망 학습의 경우에는 에포크 수를 늘리면 됨
    - 에포크(epoch) : 인공 신경망에서 전체 데이터에 대한 순전파와 역전파가 끝난 상태를 말함

- 모델 선택 문제 
  - 어떠한 학습 알고리즘을 사용하고 어떠한 파라미터를 선택해야 하는 문제
  - 이상적인 해답 : 일반화 오차를 기준으로 평가한 뒤, 일반화 오차가 가장 작은 모델을 선택하는 것
    - 일반화 오차를 직접적으로 얻을 수 없음
    - 훈련 오차에서 부딪히는 과적합 문제는 피할 수도 완벽하게 극복할 수도 없음
    
## 2.2 평가 방법
- 테스트라는 과정을 통해 학습기의 일반화 오차에 대해 평가를 진행하고 모델을 선택함
  - 테스트 세트(testing set)를 활용하여 학습기가 만나보지 못했던 새로운 샘플에서 어떻게 작동할지 예측할 수 있고 테스트 세트에서 나온 테스트 오차(testing error)를 실제 일반화 오차의 근삿값으로 생각함
- 테스트 샘플이 실제 샘플과 동일한 분포를 나타내고 있다고 가정함
- 주의해야할 점 : 테스트 세트와 훈련 세트의 중복을 최대한 피해야 함

- 우리에게 m개의 샘플을 가진 데이터 세트 D = {(x<sub>1</sub>, y<sub>1</sub>), (x<sub>2</sub>, y<sub>2</sub>),...,(x<sub>m</sub>,y<sub>m</sub>)}
  - 데이터 세트 D를 적절히 처리하여 훈련 세트 S와 테스트 세트 T로 나누는ㄴ 것
  
### 2.2.1 홀드아웃
- 홀드아웃(hold-out) 방법(검증 세트 기법) : 데이터 세트 D를 겹치지 않는 임의의 두 집합으로 나눔
  - S : 훈련 세트 집합
  - T : 테스트 세트
  - D = S ∪ T, S ∩ T = x
  - 훈련 세트 S를 통해 훈련된 모델은 테스트 세트 T를 활용해 오차를 측정하고 일반화 오차에 대한 추정치를 제공함
- 주의해야 할 것 : 훈련/ 테스트 세트를 나눌 때 되도록이면 데이터 분포가 같게 나눠야 한다는 것
  - 층화 추출법 : 양성/음성 샘플의 비중을 비슷하게 분류하는 것
  
### 2.2.2 교차 검증
- 교차 검증 
  - 데이터 세트 D를 k개의 서로소 집합으로 나누는 것으로 시작함
    - D = D<sub>1</sub> ∪ D<sub>2</sub> ∪ ... ∪ D<sub>k</sub>, D<sub>i</sub> ∩ D<sub>j</sub> = Φ (i ≠ j)
    - 매 부분집합 D<sub>i</sub>는 되도록 데이터 분포를 반영하도록 나눔
    - D로부터 층화 추출법을 통해 나누는 거
  - K-1개의 부분집합들을 훈련 세트로 사용하고 나머지 하나의 부분집합을 테스트 세트로 사용함
- K-겹 교차 검증(K-fold cross validation) : 교차 검증법을 통한 평가 결과의 안정성과 정확도는 k의 값에 따라 달라짐
  
- LOOCV(Leave-One-Out Cross Validation) : m개의 샘플이 있는 데이터 세트 D를 K=m으로 설정하고 교차 검증을 실행하는 것
  - 샘플 분류 방법에 대한 영향을 받지 않음
    - why? : m개의 샘플을 분류하는 방법은 m개의 부분집합을 만드는 것 밖에 없기 때문
    - LOOCV에 사용한 훈련 세트는 원본 데이터 세트와 비교할 때 1개의 샘플밖에 차이가 나질 않기 때문에 대부분 상황에서 LOOCV 방법을 활용한 모델은 모든 데이터 세트 D를 활용하여 훈련한 모델과 매우 비슷한 성능을 보임
      - LOOCV를 활용한 방법은 편향이 작음
  - 단점 : 데이터 세트의 크기가 매우 클 때 모델을 m번 적합해야 하므로 계산량이 많아짐
  
### 2.2.3 부트스트래핑
- 데이터 세트 D의 모든 데이터를 활용하여 훈련시킨 모델을 평가할 때 사용하는 해결책
- 부트스트래핑(bootstrapping) : 부트스트랩샘플링에 기반을 둔 샘플 추출 기법
  - m개의 샘플이 있는 데이터 세트 D를 가정한다면 우리는 샘플링을 통해 데이터 세트 D`를 만듦
  - 매번 D에서 샘플 하나를 꺼내 D`에 복사하여 넣으
  - 그리고 다시 원래의 데이터 세트 D로 돌려보냄
    - 한 번 뽑혔던 샘플도 다시 뽑힐 가능성이 있음
  - 이러한 과정을 m번 반복한 후, 우리는 m개의 샘플이 들어 있는 데이터 세트 D`를 얻음
    - 이것이 부트스트래핑의 결과
  - D의 샘플 중 일부는 D`에서 반복 출현함. 어떤 샘플은 아예 뽑히지 않을 수도 있음
  - m번의 채집 과정 중 샘플이 한 번도 뽑히지 않을 확률 : (1-1/m)m
    - 극한값을 계산 시 


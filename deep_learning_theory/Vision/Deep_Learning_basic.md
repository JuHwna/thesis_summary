# 딥러닝 기초
## 1. 딥러닝과 신경망
### 1) 퍼셉트론과 신경망
- 퍼셉트론 : 신경망의 기본 구성요소
- 퍼셉트론의 구성요소
  - 입력(inputs)
  - 가중치(Connection Weight)
  - 바이어스(bias)
  - 합 연산(Sum)
  - 활성 함수(Activation Function)
- 하나의 퍼셉트론에서 이루어지는 연산 : 입력의 가중합 -> 활성화 함수 적용(두단계)
- 하나의 퍼셉트론으로 가능한 연산과 의미
  - Linearly Separable Problem만 해결할 수 있음
    - AND연산, OR연산, NOT연산 가능
    - 최종적으로 하나의 퍼셉트론은 입력(X)의 공간에서 그려보면 하나의 직선(하이퍼 플레인)을 의미
    - 또한, 하나의 퍼셉트론은 AND, OR, NOT 연산을 통해서 Linearly Separable 문제를 해결할 수 있다는 의미
    - AND, OR, NOT 3가지 연산이 가능하다는 것 : 현재 컴퓨터에서 존재하는 3가지 기본연산을 할 수 있다는 의미
    - 퍼셉트론 여러 개를 연결하면 이론적으로 기존 컴퓨터에서 소화하는 모든 연산(함수)를 재현할 수 있다는 것을 뜻함
  - 신경망(OR 모델) : 퍼셉트론을 층 단위로 배치하고 나열하여 만들어진 아키텍처들

- 신경망으로 해결 가능한 묹들
  - 퍼셉트론 덩어리에 활성화 함수, 네트워크 구조 변경을 통해서 문제를 잘 해결할 수 있음
  - Classification(분류)
    - 데이터를 구성하는 클래스 개수와 동일하게 Output 레이어의 퍼셉트론의 개수를 정함
  - Regression(회귀)
    - 앞서 classification과는 다르게 몇 개의 노드로 구성되는지 알 수 없음
    - 넓은 숫자 범위를 가지는 활성화 함수로 변경하여 적용

### 2) 학습 알고리즘
- 딥러닝에서 말하는 학습 : 퍼셉트론 사이 모든 가중치를 주어진 데이터 맞게 셋팅하는 것
- 지도학습 학습 진행 순서
  - [순서1] : 모든 커넥션에 임의에 가중치를 부여함
    - 퍼셉트론 연산이 입력층부터 순차적으로 이루어짐
    - 이전 퍼셉트론 출력의 가중합 -> 활성화 함수 적용이 네트워크를 따라서 계속 이루어지고 마지막 퍼셉트로에서 활성화 함수를 적용한 것이 예측치가 될 거임
  - [순서2] : 가중치를 이용하여 라벨(Y)과 예측값(Prediction)의 에러(Error)를 계산함
    - 뉴럴 넷을 통해 계산된 예측치와 라벨값의 에러를 구함
    - 에러는 개발자가 선택한 특정 함수를 이용하여 계산됨
      - 에러 함수(=목적함수=로스펑션)
        - 보통 로스 평션이라고 부름 : 함수의 출력값(Loss)이 클수록 라벨과의 차이가 크다는 것을 의미함
        - 학습 알고리즘은 반복을 통해 이 로스 값이 최소가 되도록 가중치를 조금씩 변경함
      - 딥러닝에서 중요한 부분 중에 하나는 이 에러를 구하는 함수를 정의하는 것
      - 어떤 함수를 정의하느냐에 따라 최종적으로 신경망에 업데이트되는 가중치의 값이 달라짐
      - 딥러닝의 학습 메커니즘이 에러 함수 값을 최대화 혹은 최소화하도록 구성되어 있음
        - 분류 문제의 경우, Cross Entropy Error를 이용. 회귀 문제의 경우, Mean Squared Error 이용
  - [순서3] : 에러를 가중치로 미분하여 기울기를 구함
    - 에러(로스펑션)의 구성
      - 가중치들의 함수(X,Y값은 고정된 상수, 가중치들만이 고정되지 않은 변수)
    - 학습의 목적
      - 주어진 데이터(X,Y)에 대해서 가중치들을 적절히 셋팅해서 에러가 최소가 되도록 하는 것
      - 미분해서 0이 되는 가중치를 찾는 것이 불가능 -> 이유 : 수백만개의 변수들이 엉켜있어 단순한 뉴럴넷이 아닌 이상 불가능
        - 대신 최적해(Global optimum)를 찾는 것이 아니라 반복을 통해서 그 중에서 제일 로스값을 작게 만드는 가중치(Local optimum)를 찾는 것은 가능함
    - 현재위치 기울기의 반대방향으로 가중치를 이동하면 에러 감소
  - [순서4] : 기울기에 작은 상수를 곱하고 이 값을 기존 가중치에서 빼주어 가중치를 업데이트함
    - 가중치 방향을 알았으면 이동할 크기를 정해야 함
    - 가중치의 이동할 양 : 개발자가 결정함
      - 크게 이동하면 많이 어긋남
      - 보통은 작은 값으로 선택함
      - 선택한 작은 값에 기울기의 반대방향을 곱하고 이 크기만큼 가중치를 이동함
  - [순서4] ->[순서2]로 돌아감
  -      
### 3) 활성화 함수
- 퍼셉트론의 출력값 : Activation Function(모든 퍼셉트론 입력의 가중함)
- 활성화 함수의 종류와 선택
  - 신경망을 개발할 때 사람이 선택 가능함
  - 활성화 함수의 ㅅ너택은 신경망의 예측 성능에 영향을 미침
  - 최소한 활성화 함수 출력 범위 내에 라벨값(Y)들이 포함되어 있어야 정상적인 학습이 가능
- 활성화 함수는 왜 필요할까?
  - 활성화 함수는 신경망에 비선형성을 더해줌
    - 주어진 데이터를 설명하는 복잡한 형상의 선이나 경계면을 찾는데 도움을 줌

### 4) 로스펑션
- 로스 펑션(=에러 함수)
  - 로스(Loss) : 라벨값과 예측값의 차이
  - 로스 펑션 : 라벨값과 예측값의 차이를 계산하기 위한 함수
  - 학습 진행 : 로스를 최소화하는 방향으로 가중치를 업데이트하며 진행
    - 로스 펑션을 제대로 정하는 것이 매우 중요함
- Mean Squared Error
  - $$MSE=\frac{1}{n}\sum(Label-Pred)^2$$
- Cross Entropy
  - $$CE = -\sum(Label)*log(pred)$$
  - 정답 클래스의 확률을 낮게 계산할수록 로스 값이 크게 계산되는 형식

### 5) 옵티마이저(Optimizer)
- 뉴럴넷의 가중치를 업데이트하는 알고리즘
- 가중치를 업데이트하는 방법
  - 경사하강법에서 생기는 여러가지 단점을 극복하기 위해 다양한 알고리즘이 제안됨

- GD(Gradient Descent)의 문제점
  - 모든 데이터를 다 계산하고 발생한 모든 에를 합하여 가중치를 업데이트함
    - 실제 학습에 사용하기에는 큰 문제가 발생
    - 뉴럴넷이 성능을 발휘하기 위해 가중치를 업데이트하기 위해서는 전체 데이터셋을 이용하여 수십번의 가중치를 업데이트해야함
    - GD의 경우 너무 느리고 메모리 소모가 많음
      - EX) 1000개의 데이터셋이 존재하고 뉴럴넷의 가중치가 200개 존재할 때
        - 1 epoch에 1번의 update가 이뤄지고, 한 번의 변화를 이루기 위해 약 100*200번의 gradient 계산이 필요함
    - 1 epoch : 트레이닝 데이터를 모두 활용하여 학습을 진행하는 것
- SGD(Stochastic Gradient Descent)
  - 전체가 아니라 배치(batch)단위로 가중치 업데이트하자는 아이디어
    - 배치 : 전체 데이터를 동일한 숫자로 나눈 것
    - ex) 1000개의 데이터셋을 200개 1배치로 묶으면 1 epoch당 총 5번의 업데이트가 일어남
- GD,SGD의 개선
  - 2가지 방법을 사용해서 옵티마이저의 성능을 개선시킴
  - (1) 과거의 진행방향을 참고하는 관성(Momentum)을 사용함 (ex) Momentum, NAG
  - (2) 이제까지 계산된 Gradient에 따라 다른 학습률(Adaptive Learning Rate)을 가지도록 함 (ex) Adagrad, RMSProp
  - (3) 관성(Momentum)과 스텝사이즈 변화(Adaptive Learning Rate) 두 가지를 다 고려함 (ex)Adam

- Momentum
  - 물리의 관성 개념을 옵티마이저에 적용했음
  - step에서의 gradient와 이제까지의(과거) 이동한 gradient의 exponential average를 더해줌
    - 과거의 gradient의 파라미터(y)로 조절하여 더해줌
    - Gradient Descent 식
      - $$X_1=X_0-\alpha*f(x_0)$$
      - $$x_2=x_1-\alpha*f(x_1)$$
    - Momentum
      - $$X_1=X_0-\alpha*f(x_0)$$
      - $$x_2=x_1-\alpha*f(x_1)+momentum$$
  - 장점(SGD가 가지지 못했던 장점을 가질 수 있음)
    - (1) 관성이 붙어 Local optimum을 벗어날 수도 있음
    - (2) 궤적이 크게 변동하지 않아 SGD보다 안정적으로 Gradient가 하강됨
  - 단점
    - 가중치의 이동량을 계산하기 위해 Momentum과 Gradient 두 가지를 한 번에 업데이트해야함
      - 즉, 업데이트가 과도하게 계산될 수 있음
- Nesterov Accelerated Gradient(NAG)
  - 업데이트가 과도하게 계산되는 것을 줄이기 위해 Momentum과 Gradient의 순서를 분할함
    - 현재 위치에서 t시점으로 Momentum만 계산하여 이동하고 이동한 곳을 기준으로 Gradient를 계산하여 두 번째로 이동함
    - 식 : $$X_{n+1}=X_n-\alpha\beta a_n-\alpha\nabla f(x_n-\alpha\beta a_n)$$
  - 한 번에 먼 이동이 아니라 순서를 나누어 이동하므로 Momentum보다 부드러운 궤적을 가지게 되고 모멘텀과 같이 과도한 업데이트가 일어나지 않음

- Adagrad
  - 기존에 상수였던 학습률(learing rate)를 선택적으로 조절하는 옵티마지어임
  - SGD with Momentum
    - $$v_{t+1} \gets \rho v_t+\nabla_\theta L(\theta)$$
    - $$\theta_j \gets \theta_j - \epsilon v_{t+1}$$
  - AdaGrad
    - $$g_0 =0$$
    - $$g_{t+1} \gets g_t + \nabla_\theta L(\theta)^2$$
    - $$\theta_j \gets \theta_j - \epsilon*\frac{\nabla_\theta L(\theta)^2}{\sqrt g_{t+1}+1e^{-5}}$$
  - 현 시점까지의 계산되었던 모든 Gradient의 제곱합에 반비례하는 학습률을 가짐
    - 학습이 진행될수록 이동량이 줄어들게 됨
    - 이때문에 Global Optimum 근처에서 이동량 감소면 좋은 경우임
    - 하지만 Global Optimum 근처까지 도달하지 못했는데도 이동량이 줄어들면 큰 단점이 됨
- RMSProp
  - Adagrad의 단점을 개선한 옵티마이저
  - 과거 Gradient의 값들과 현재 Gradient값들의 비율을 하이퍼파라미터로 조절함
  - 식
    - $$\theta_t =\theta_{t-1} - \frac{\eta}{\sqrt v_t} g_{t-1}$$
    - $$v_t = \beta_2 v_{t-1}+(1-\beta_2)(g_{t-1})^2 $$
    - $$v_1=(g_0)^2$$
- Adam
  - RMSProp+Momentum
  - Adaptive Learning rate와 Momentum개념이 합쳐진 옵티마이저
    - 두 가지가 합쳐졌기에 하이퍼 파라미터는 두 개를 가짐
  - 식
    - $$m_0 =0, v_0 = 0$$
    - $$m_{t+1} \gets \beta_1m_t+(1-\beta_1)\nabla_\theta L(\theta)$$ -> momentum
    - $$v_{t+1} \gets \beta_2v_t+(1-\beta_2)\nabla_\theta L(\theta)^2$$ -> RMS Prop
    - $$\theta_j \gets \theta_j - \frac{\epsilon}{\sqrt v_{t+1}+1e^{-5}} m_{t+1}$$ -> RMS Prop+Momentum
### 6) 딥러닝 테크닉
- 딥러닝의 성능과 학습을 위해 개발된 방법들
- 기울기 사라짐(Gradient Vani
      

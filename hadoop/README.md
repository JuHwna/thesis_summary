# Hadoop
## 1. 정의 및 특징
(1) Hadoop : 안정적이고 확장성이 높은 저장 및 분석 플랫폼
  - 특징
     1. 강력한 병렬 프로세싱 프레임워크를 구현하기 위한 플랫폼을 제공하는 분산 데이터 스토어
     2. 노드를 추가하는 Scale-out 방식
     3. 아주 큰 규모의 데이터를 저장하는 경우, 일어날 수 있는 장애에 대응하여 데이터 손실을 감소시키고 분할된 데이터를 계산할 수 있는 인터페이스가 존재
  - 점점 진화해나가는 하둡 에코 시스템
     1. 기존의 하둡 : HDFS, 맵리듀스
        - 일괄 처리 담당
     2. 최근의 하둡 : 수많은 에코시스템 등장
        - 대화형 SQL, 스트림 처리 등 다양한 처리 패턴을 제공
     - 하둡 에코시스템이 진화하는 것에 따라 분산 컴퓨팅과 대규모 데이터 처리를 위한 기반이 더욱 견고해져가고 있음
![image](https://user-images.githubusercontent.com/49123169/234770028-03f22ee2-b214-41e6-b401-7cdc87138bc8.png)

(2) HDFS : 하둡의 스토리지를 담당
  - HDFS 정의 : 하둡 분산 파일 시스템
    - 세부 내용 : 하둡의 파일시스템, 분산 파일 시스템으로써 **네트워크로 연결된 여러 머신의 스토리지를 관리**하는 파일 시스템
  - 설계 방식 : 한 번 쓰고 여러 번 읽자!
    - 세부 내용 : 큰 파일들을 여러 머신에 나누어 저장하기 위해 설계되었으며, '한 번 쓰고 여러 번 읽는 것'에 중점을 둠
  - 구성 : 네임노드와 데이터 노드
    - 세부 내용
      - 네임 노드 : 파일 시스템 트리와 모든 파일과 디렉터리에 대한 메타데이터 유지
      - 데이터 노드 : 클라이언트와 네임노드의 요청으로 인한 블록 저장과 탐색을 저장 

(3) 하둡의 계산을 담당하는 맵리듀스
  - 맵 단계
    - 인풋 데이터를 가공하여 사용자가 원하는 정보를 (Key, Value) 쌍으로 변환
  - 리듀스 단계
    - 가공된 (Key, Value)를 Key 기준으로 각 리듀스로 분배하고 사용자가 정의한 방법으로 각 Key 관련된 정보를 추출

![image](https://user-images.githubusercontent.com/49123169/234771250-078bcdec-1560-4f4d-9692-b74cac1e1964.png)

- 맵리듀스 과정 비유
![image](https://user-images.githubusercontent.com/49123169/234771349-15ec14a1-2810-4c82-9143-e90344893788.png)

- 결론 : HDFS와 맵리듀스 => 하둡의 기본! 하둡의 짝꿍


## 2. 수많은 데이터를 어떻게 하둡에서 쓸 수 있을까?
(1) 스쿱(SQOOP) : RDBMS와 하둡 사이의 데이터를 이동
- 정의 : RDBMS와 하둡 사이에 데이터 이동을 지원하는 스쿱
   1. RDBMS의 데이터를 HDFS, Hive, HBase에 import/export할 수 있음
   2. RDBMS를 읽고 쓸 수 있는 커넥터가 각 DB별로 존재
- 스쿱을 잘 쓰기 위한 조건
   1. Mapper 관리
   2. 병렬처리
   3. 병목현상 진단
   4. 하둡 최신상태 유지
   
(2) Kafka(카프카) : 분산 메시지 버스
1. 링크드인에서 여러 구직, 채용 정보들을 한 곳에서 처리할 수 있는 플랫폼 개발
2. 대용량의 실시간 로그 처리에 특화되어 설계된 메시징 시스템
- 단 시간 내에 엄청난 양의 데이터와 다양한 유형의 데이터를 실시간으로 수집
3. Consumer가 서버로부터 직접 메시지를 가져오는 Pull 방식
- Consumer가 자신의 처리 능력만큼 메시지를 가져오므로 최적의 성능을 냄

- 카프카 적용 사례
  - Case 1. 카프카로부터 온 메시지를 HDFS에 저장해 분석 및 리포팅에 사용
  - Case 2. 실시간 스트림 프로세싱
  
- 결론 : 스쿱이란 RDBMS와 하둡 사이의 연결고리
  - 카프카란 실시간 스트림 프로세싱 분야에서 하둡같은 존재
  

## 3. SQL 문법으로 하둡 클러스터에 있는 데이터를 검색할 수 있는 HIVE
(1) HIVE
- 정의 : 하둡 데이터(파일)를 SQL로 다룰 수 있게 해 주는 툴
  1. 하둡 클러스터에 있는 데이터를 검색하기 위해 SQL 호환 언어(HiveQL, HQL)를 제공
  2. 대부분의 쿼리를 맵리듀스로 변환
- 익숙한 SQL 문법으로 데이터를 분석하려고
  1. SQL은 데이터를 구성, 검색하는 방법으로 널리 사용되고 있었음
  2. 데이터 분석가들이 익숙한 SQL문법으로 하둡에서 데이터 분석을 할 수 있도록 만들기 위해 페이스북에서 시작
  
- SQL을 지원하는 HIVE, 데이터 웨어하우스 어플리케이션에 아주 적합
  - 하이브의 쿼리 응답시간은 전통 데이터베이스보다 긴 편
    - 빠른 응답 시간이 필요하지 않은 데이터웨어 하우스 애플리케이션에 적합
  - 데이터 웨어하우스 애플리케이션의 특징
     1. 비교적 정적 데이터를 분석
     2. 빠른 응답 시간 필요하지 않음
     3. 데이터가 자주 바뀌지 않음
     
- 결론 : HIVE란 맵리듀스와 Java 프로그래밍을 SQL로 대신할 수 있는 툴!

## 4. 아주 큰 대용량 데이터를 랜덤 액세스할 수 있는 HBase
- SQL? 그럼 No SQL은?
- RDBMS가 할 수 없었던 것들을 간단하고, 빠르게 처리할 수 있도록!
- HBase 정의 : 분산 NoSQL 데이터 스토어
  1. 데이터를 다수의 Region Server에 분산 보관하고, 자주 접근되는 데이터를 메모리에 캐시
  2. 컬럼 패밀리 사용, 하나의 row에 많은 column 저장, 스키마 없음, 조인 인덱스 없음, 행 단위의 조작에 대해서만 atomic 보장
  3. 물리적 저장소로 HDFS를 사용함
- 간단한 스키마로 데이터를 신속, 정확하게
  1. 완벽한 ACID를 보증하는 접근 방법이 아니라 일단 간단한 스키마로 결과를 빠르게 조회할 수 있는 조회 속도 관점에서의 실시간성 데이터베이스에 대한 요구
  2. 하둡과의 긴밀한 연관성에 대한 요구

- 빠른 검색이 필요한 곳에서는 HBase
  1. HDFS와 맵리듀스는 각각의 레코드를 효과적으로 읽거나 쓰는 방법을 제공하지 않음
     - 대형 테이블에 대한 빠른 레코드 검색이 비효율적임
  2. HBase는 빠른 Write와 Read를 지원
     - 특정 데이터 셀에 키 기반으로 접근하거나 어떤 범위의 셀에 순차적으로 접근하는데 탁월한 성능을 제공
- 결론 : HBase란 대규모 데이터셋에 실시간 랜덤 액세스를 가능하게 해주는 역할

## 5. 무한대의 데이터 스트림을 하둡의 배치 프로세싱처럼 실시간으로 처리하는 Storm
- 데이터가 들어오자마자 처리 결과를 볼 수 있을까요?
- Storm 정의 : 이벤트 스트림 프로세싱을 위한 분산현 컴퓨팅 프레임워크
  1. 강력한 확장성
     - 대용량의 메시지를 효과적으로 병렬처리할 수 있도록 설계
     - 새로운 노드 추가 방식으로 간단히 확장 가능
  2. 폴트 톨러런스(빠른 실패, 자동 재시작) 지원
     - 장애가 발생한다고 가정하고 아키텍처를 구성
  3. 모든 튜플의 처리를 보증
     - 최소 한 차례 이상 메시지를 보증하도록 디폴트 되어 있음
  4. 풍부한 스파웃 有
     - 트위터 스트리밍 API, 아파치 카프카, JMS 브로커 등 다양한 인풋스트림 제공
  5. 스파크보다 많은 언어 지원
- 요약 : 확장성이 아주 크고 빠르며 내결함성이 강한 스트림 프로세싱에 초점이 맞춰진 분산형 컴퓨팅을 위한 오픈소스 시스템
 
  3. 

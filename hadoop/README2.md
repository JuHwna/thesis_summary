# 하둡 에코시스템 아키텍처
- 맵리듀스와 HDFS 같은 Core 모듈 외에 보완적인 서비스를 제공하거나 비즈니스에 활용가능한 서브 프로젝트들로 구성된 집합

![image](https://user-images.githubusercontent.com/49123169/234797409-e57733ec-9001-45e0-8a43-c5d0f986c009.png)


- 하둡 에코 시스템의 구성 : 관리 모니터링 툴, NoSQL 데이터베이스, 데이터 처리, 데이터 수집 도구 등으로 구성


- 관리도구
  - Zookeeper(분산 코디네이션)
    - 분산환경에도 동작하는 서버들 간에 상호 조정이 필요한 기능들을 관리하고 서비스를 적절히 분산하여 처리되도록 동기화를 담당하는 모듈
  - Ambari(관리 및 모니터링)
    - 하둡 시스템을 직관적인 UI를 통해 통합 관리하기 위한 프로그램
    - REST API 제공
    - 아래 UI에서 보는 것처럼 각 서브 모듈들의 상태를 한눈에 그래프 등을 통해 체크 가능
    - ![image](https://user-images.githubusercontent.com/49123169/234798308-be05d722-4c52-4ea1-92df-9b0f6fef371c.png)
    - Ambari 특징
      - 설치 및 구성의 간소화(대규모 클러스터의 효율적 생성, 관리 가능)
      - 중앙집중식 보안 설정
      - 클러스터 전체 status를 가시적으로 확인

- 데이터베이스
  - 카산드라
    - 페이스북에 의해 개발되어 공개된 JAVA 기반의 오픈소스 DB
    - 트위터에서 기존 사용되던 MySQL을 Cassandra 기반으로 전환한 것
    - 장점 : 트위터와 같은 대량 write 트랜잭션 기반에 효율이 좋음
    - 단점 : 복잡한 검색이 어려우며, 데이터 갱신 시 배타적인 처리가 어려움
  - HBase
    - 하둡의 하위 프로젝트로 개발되어 대량의 데이터 분석 처리에 효과적인 분산 DB
    - 하둡의 MapReduce와 유기적으로 결합되어 처리 시 상호 운영성이 좋음
    - 단점 : 대규모 데이터 처리 전용이라는 한계, 성능이 상대적으로 빠르지 않다는 것
  - MongoDB
    - 장점 : 대량의 데이터 처리에 적합, 속도가 매우 빠름
    - 단점: 금융 데이터와 같이 일관성이 중시되는 DB로 사용되기는 어려움

- 데이터 수집 도구
  - 정형데이터, 비정형 데이터의 수집과 처리 그리고 대용량 데이터의 HDFS 분산파일시스템 저장을 담당
  - Chukwa : 비정형 데이터의 처리를 담당
    - 분산 서버에서 agent를 실행하여 수집을 담당하는 collector로부터 데이터를 받아 HDFS에 저장함
    - 이 외에 비정형 데이터수집 모듈로는 Flume, Scribe 등
  - Sqoop : 정형 데이터의 처리를 담당
    - RDB에서 관리되는 정형 데이터를 분산파일 시스템 HDFS로 import, export를 수행하는 모듈
    - 이 외에 Hiho

- 데이터 처리 도구
  - Mahout
    - 데이터 추천, 분류, 군집 분석과 같은 통계적 분석 도구 및 머신러닝 라이브러리 등을 포함한 오픈 소스 프레임워크
    - 구성요소 : 추천, 분류, 군집
  - Hive
    - 하둡 기반의 DW(데이터 웨어하우스) 소류션의 일종
    - SQL과 유사하여 Hive SQL이라고도 불리며 쿼리를 통해 하두둡
    
